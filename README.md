# Visualize

Interpretability of Deep Learning Models with Tensorflow 2.0

## Activations Visualization

> Visualize how a given input comes out of a specific activation layer

<p align="center">
    <img src="./docs/assets/activations_visualisation.png" width="500" />
</p>


## Roadmap

- [x] Activations Visualization
- [ ] Convolutional Kernel Visualizations
- [x] Occlusion Sensitivity Maps
- [ ] Saliency Maps
- [ ] Grad-CAM
