# Visualize

Interpretability of Deep Learning Models with Tensorflow 2.0

## Activations Visualization

| Visualize how a given input comes out of a specific activation layer

![Activations Visualisation](./docs/assets/activations_visualisation.png "Activations Visualisation")


## Roadmap

- [x] Activations Visualization
- [ ] Convolutional Kernel Visualizations
- [x] Occlusion Sensitivity Maps
- [ ] Saliency Maps
- [ ] Grad-CAM
